\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{spanish}{}
\@writefile{toc}{\contentsline {chapter}{Introducci\IeC {\'o}n}{7}{chapter*.3}}
\citation{bellman1957theory}
\citation{sutton2018reinforcement}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introducci\IeC {\'o}n al aprendizaje por refuerzo}{9}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Proceso de decisi\IeC {\'o}n de Markov}{9}{section.1.1}}
\@writefile{thm}{\contentsline {defi}{{Definición}{1.1.{1}}{Proceso de decisión de Markov}}{9}{defi.1.1.1}}
\newlabel{pdynamics}{{1.1.1}{9}{Proceso de decisión de Markov}{equation.1.1.1}{}}
\@writefile{thm}{\contentsline {obs}{{Observación}{1.1.{1}}{}}{9}{obs.1.1.1}}
\newlabel{p(s'|s,a)}{{1.1.2}{10}{Proceso de decisión de Markov}{equation.1.1.2}{}}
\@writefile{thm}{\contentsline {obs}{{Observación}{1.1.{2}}{}}{10}{obs.1.1.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Notaci\IeC {\'o}n de distribuciones de probilidad.\relax }}{10}{table.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{DisNot}{{1.1}{10}{Notación de distribuciones de probilidad.\relax }{table.caption.4}{}}
\newlabel{r(s,a)}{{1.1.4}{10}{Proceso de decisión de Markov}{equation.1.1.4}{}}
\@writefile{thm}{\contentsline {obs}{{Observación}{1.1.{3}}{}}{10}{obs.1.1.3}}
\@writefile{thm}{\contentsline {defi}{{Definición}{1.1.{2}}{Regla de decisión}}{10}{defi.1.1.2}}
\@writefile{thm}{\contentsline {defi}{{Definición}{1.1.{3}}{Política}}{10}{defi.1.1.3}}
\@writefile{thm}{\contentsline {example}{{Ejemplo}{1.1.{1}}{Control de una partícula}}{10}{example.1.1.1}}
\newlabel{ControlParticula}{{1.1.{1}}{10}{Proceso de decisión de Markov}{example.1.1.1}{}}
\newlabel{deltas}{{1.1.8}{11}{Proceso de decisión de Markov}{equation.1.1.8}{}}
\newlabel{deltar}{{1.1.10}{11}{Proceso de decisión de Markov}{equation.1.1.10}{}}
\citation{bellman1954theory}
\citation{bellman1957theory}
\newlabel{graphMDP}{{1.1a}{12}{Proceso de decisión de Markov.\relax }{figure.caption.5}{}}
\newlabel{sub@graphMDP}{{a}{12}{Proceso de decisión de Markov.\relax }{figure.caption.5}{}}
\newlabel{EvolutionMDP}{{1.1b}{12}{Evolución del sistema bajo una política.\relax }{figure.caption.5}{}}
\newlabel{sub@EvolutionMDP}{{b}{12}{Evolución del sistema bajo una política.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Proceso de desici\IeC {\'o}n de Markov para el ejemplo (\ref  {ControlParticula}) \relax }}{12}{figure.caption.5}}
\newlabel{MDPfig}{{1.1}{12}{Proceso de desición de Markov para el ejemplo (\ref {ControlParticula}) \relax }{figure.caption.5}{}}
\@writefile{thm}{\contentsline {defi}{{Definición}{1.1.{4}}{}}{12}{defi.1.1.4}}
\@writefile{thm}{\contentsline {obs}{{Observación}{1.1.{4}}{}}{12}{obs.1.1.4}}
\@writefile{thm}{\contentsline {obs}{{Observación}{1.1.{5}}{Recurencia del retorno esperado}}{12}{obs.1.1.5}}
\newlabel{Gttt}{{1.1.14}{12}{Proceso de decisión de Markov}{equation.1.1.14}{}}
\@writefile{thm}{\contentsline {problem}{{Problema}{1.1.{1}}{}}{12}{problem.1.1.1}}
\newlabel{eq:OCP}{{1.1.15}{12}{Proceso de decisión de Markov}{equation.1.1.15}{}}
\@writefile{thm}{\contentsline {defi}{{Definición}{1.1.{5}}{}}{12}{defi.1.1.5}}
\citation{LAZARIC}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Programaci\IeC {\'o}n din\IeC {\'a}mica}{13}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Funciones valor estado ($v^\pi $)}{13}{subsection.1.2.1}}
\@writefile{thm}{\contentsline {defi}{{Definición}{1.2.{1}}{Función valor de estado}}{13}{defi.1.2.1}}
\newlabel{defi:valorstado}{{1.2.{1}}{13}{Funciones valor estado ($v^\pi $)}{defi.1.2.1}{}}
\@writefile{thm}{\contentsline {obs}{{Observación}{1.2.{1}}{}}{13}{obs.1.2.1}}
\@writefile{thm}{\contentsline {defi}{{Definición}{1.2.{2}}{Función valor de estado óptima}}{13}{defi.1.2.2}}
\newlabel{valorestadoopt}{{1.2.2}{13}{Funciones valor estado ($v^\pi $)}{equation.1.2.2}{}}
\@writefile{thm}{\contentsline {cor}{{Colorario}{1.2.{1}}{Ecuación de Bellman}}{13}{cor.1.2.1}}
\newlabel{BellmanEquation}{{1.2.5}{13}{Funciones valor estado ($v^\pi $)}{equation.1.2.5}{}}
\newlabel{BellmanEquation}{{1.2.6}{13}{Funciones valor estado ($v^\pi $)}{equation.1.2.6}{}}
\@writefile{thm}{\contentsline {cor}{{Colorario}{1.2.{2}}{Ecuación de Bellman óptima}}{14}{cor.1.2.2}}
\newlabel{BellmanEquationOptimo}{{1.2.8}{14}{Funciones valor estado ($v^\pi $)}{equation.1.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Funci\IeC {\'o}n valor de estado-accion ($q^\pi $)}{14}{subsection.1.2.2}}
\@writefile{thm}{\contentsline {defi}{{Definición}{1.2.{3}}{Función valor de estado-acción}}{14}{defi.1.2.3}}
\@writefile{thm}{\contentsline {defi}{{Definición}{1.2.{4}}{Función valor de estado-acción óptima}}{14}{defi.1.2.4}}
\newlabel{qopt}{{1.2.11}{14}{Función valor de estado-accion ($q^\pi $)}{equation.1.2.11}{}}
\newlabel{qv}{{1.2.14}{14}{Función valor de estado-accion ($q^\pi $)}{equation.1.2.14}{}}
\citation{LAZARIC}
\citation{banach1922operations}
\newlabel{qoptvopt2}{{1.2.17}{15}{Función valor de estado-accion ($q^\pi $)}{equation.1.2.17}{}}
\@writefile{thm}{\contentsline {cor}{{Colorario}{1.2.{3}}{Relación entre funciones valor óptimas}}{15}{cor.1.2.3}}
\newlabel{voptqopt}{{1.2.18}{15}{Función valor de estado-accion ($q^\pi $)}{equation.1.2.18}{}}
\@writefile{thm}{\contentsline {cor}{{Colorario}{1.2.{4}}{Ecuación de Bellman estado-acción óptima}}{15}{cor.1.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Operadores de Bellman (OB)}{15}{subsection.1.2.3}}
\@writefile{thm}{\contentsline {defi}{{Definición}{1.2.{5}}{OB de estado óptimo}}{15}{defi.1.2.5}}
\@writefile{thm}{\contentsline {thm}{{Teorema}{1.2.{1}}{Punto Fijo de Banach \cite {banach1922operations}}}{15}{thm.1.2.1}}
\citation{sutton2018reinforcement}
\@writefile{thm}{\contentsline {defi}{{Definición}{1.2.{6}}{OB de estado-acción óptimo}}{16}{defi.1.2.6}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Algoritmos de aprendizaje por refuerzo}{16}{section.1.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces \emph  {Value Iteration}\relax }}{16}{algorithm.1}}
\newlabel{ValueIteration}{{1}{16}{\emph {Value Iteration}\relax }{algorithm.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces \emph  {Q-Iteration}\relax }}{17}{algorithm.2}}
\newlabel{QIteration}{{2}{17}{\emph {Q-Iteration}\relax }{algorithm.2}{}}
\@writefile{thm}{\contentsline {example}{{Ejemplo}{1.3.{1}}{Movimiento de una partícula en un potencial}}{17}{example.1.3.1}}
\newlabel{ParticulaPotencial}{{1.3.{1}}{17}{}{example.1.3.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces \emph  {Q learning}\relax }}{18}{algorithm.3}}
\newlabel{Qlearning}{{3}{18}{\emph {Q learning}\relax }{algorithm.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Comportamiento de la part\IeC {\'\i }cula en un potencial}}{19}{figure.caption.6}}
\newlabel{fig:potencial}{{1.2}{19}{Comportamiento de la partícula en un potencial}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Evoluci\IeC {\'o}n de la funci\IeC {\'o}n vlaor por \emph  {Value Iteration}}}{19}{figure.caption.7}}
\newlabel{fig:valueiteration}{{1.3}{19}{Evolución de la función vlaor por \emph {Value Iteration}}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Evoluci\IeC {\'o}n de la pol\IeC {\'\i }tica por \emph  {Value Iteration}}}{20}{figure.caption.8}}
\newlabel{fig:piiteration}{{1.4}{20}{Evolución de la política por \emph {Value Iteration}}{figure.caption.8}{}}
\newlabel{afree}{{1.5a}{20}{Espacio de fases sin control\relax }{figure.caption.9}{}}
\newlabel{sub@afree}{{a}{20}{Espacio de fases sin control\relax }{figure.caption.9}{}}
\newlabel{bLQR}{{1.5b}{20}{Espacio de fases con LQR\relax }{figure.caption.9}{}}
\newlabel{sub@bLQR}{{b}{20}{Espacio de fases con LQR\relax }{figure.caption.9}{}}
\newlabel{cQI}{{1.5c}{20}{Espacio de fases con \emph {Value Iteration}\relax }{figure.caption.9}{}}
\newlabel{sub@cQI}{{c}{20}{Espacio de fases con \emph {Value Iteration}\relax }{figure.caption.9}{}}
\newlabel{cQI}{{1.5d}{20}{Espacio de fases con \emph {Q learning}\relax }{figure.caption.9}{}}
\newlabel{sub@cQI}{{d}{20}{Espacio de fases con \emph {Q learning}\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Espacio de fases modificado}}{20}{figure.caption.9}}
\newlabel{fig:potencial}{{1.5}{20}{Espacio de fases modificado}{figure.caption.9}{}}
\citation{schafer2007collaborative}
\citation{lops2011content}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Introduci\IeC {\'o}n a Sistemas de recomendaci\IeC {\'o}n}{21}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Filtrado colaborativo}{21}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Filtrado basado en contenido}{21}{section.2.2}}
\citation{shani2005mdp}
\citation{shani2005mdp}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Sistema de basado en un proceso de decici\IeC {\'o}n de Markov}{22}{section.2.3}}
\citation{MovieLens}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Preprocesado del historial de pel\IeC {\'\i }culas}{23}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Descripci\IeC {\'o}n de la base de datos iniciales}{23}{section.3.1}}
\@writefile{thm}{\contentsline {db}{{Base de datos}{3.1.{1}}{movies.csv}}{23}{db.3.1.1}}
\newlabel{movies}{{3.1.{1}}{23}{Descripción de la base de datos iniciales}{db.3.1.1}{}}
\@writefile{thm}{\contentsline {db}{{Base de datos}{3.1.{2}}{ratings.csv}}{23}{db.3.1.2}}
\newlabel{ratings}{{3.1.{2}}{23}{Descripción de la base de datos iniciales}{db.3.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Union de base de datos de generos y puntaciones}{23}{section.3.2}}
\citation{MATPCA}
\@writefile{thm}{\contentsline {db}{{Base de datos}{3.2.{1}}{movies\_features.csv}}{24}{db.3.2.1}}
\newlabel{moviesref}{{3.2.{1}}{24}{Union de base de datos de generos y puntaciones}{db.3.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Normalizaci\IeC {\'o}n de puntaci\IeC {\'o}n de las pel\IeC {\'\i }cula}{24}{section.3.3}}
\@writefile{thm}{\contentsline {db}{{Base de datos}{3.3.{1}}{ratings\_norm.csv}}{24}{db.3.3.1}}
\newlabel{ratingsnorm}{{3.3.{1}}{24}{Normalización de puntación de las película}{db.3.3.1}{}}
\@writefile{thm}{\contentsline {obs}{{Observación}{3.3.{1}}{}}{24}{obs.3.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Componentes principales para generos de pel\IeC {\'\i }culas}{24}{section.3.4}}
\@writefile{thm}{\contentsline {db}{{Base de datos}{3.4.{1}}{movies\_pca.csv}}{24}{db.3.4.1}}
\newlabel{movierefPCA}{{3.4.{1}}{24}{Componentes principales para generos de películas}{db.3.4.1}{}}
\newlabel{VarExp}{{3.1a}{25}{Variabilidad Explicada\relax }{figure.caption.10}{}}
\newlabel{sub@VarExp}{{a}{25}{Variabilidad Explicada\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Analisis PCA en los generos de pel\IeC {\'\i }culas\relax }}{25}{figure.caption.10}}
\newlabel{}{{3.1}{25}{Analisis PCA en los generos de películas\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Historial de aceptaci\IeC {\'o}n para cada usuario}{25}{section.3.5}}
\@writefile{thm}{\contentsline {db}{{Base de datos}{3.5.{1}}{user\_movies\_accept.csv}}{25}{db.3.5.1}}
\newlabel{user_movies_features}{{3.5.{1}}{25}{Historial de aceptación para cada usuario}{db.3.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Generaci\IeC {\'o}n sint\IeC {\'e}tica del historial de rechazo}{25}{section.3.6}}
\citation{MovieLens}
\@writefile{thm}{\contentsline {db}{{Base de datos}{3.6.{1}}{user\_movies\_reject.csv}}{26}{db.3.6.1}}
\newlabel{user_movies_features_reject}{{3.6.{1}}{26}{Generación sintética del historial de rechazo}{db.3.6.1}{}}
\@writefile{thm}{\contentsline {obs}{{Observación}{3.6.{1}}{}}{26}{obs.3.6.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Bases de datos finales: Historiales de usuarios}{26}{section.3.7}}
\newlabel{HObt}{{3.7}{26}{Bases de datos finales: Historiales de usuarios}{section.3.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Diagrama de flujo para el preprocesado de los datos.\relax }}{27}{figure.caption.11}}
\newlabel{DFPrePro}{{3.2}{27}{Diagrama de flujo para el preprocesado de los datos.\relax }{figure.caption.11}{}}
\citation{shani2005mdp}
\citation{WikiRF}
\citation{WikiRF}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Sistema de recomendaci\IeC {\'o}n como proceso de decisi\IeC {\'o}n de Markov }{29}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Proceso de decisi\IeC {\'o}n de Markov}{29}{section.4.1}}
\@writefile{thm}{\contentsline {obs}{{Observación}{4.1.{1}}{}}{29}{obs.4.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Plantamiento de los problemas}{29}{section.4.2}}
\citation{fujimoto2019off}
\citation{fujimoto2019off}
\newlabel{fig:WikiRF}{{4.1a}{30}{Esquema estándar del aprendizaje por refuerzo \cite {WikiRF}\relax }{figure.caption.12}{}}
\newlabel{sub@fig:WikiRF}{{a}{30}{Esquema estándar del aprendizaje por refuerzo \cite {WikiRF}\relax }{figure.caption.12}{}}
\newlabel{afree}{{4.1a}{30}{Esquema estándar del aprendizaje por refuerzo \cite {WikiRF}\relax }{figure.caption.12}{}}
\newlabel{sub@afree}{{a}{30}{Esquema estándar del aprendizaje por refuerzo \cite {WikiRF}\relax }{figure.caption.12}{}}
\newlabel{sqmrs}{{4.1b}{30}{Esquema específico de aprendizaje por refuerzo en el sistema de recomendación.\relax }{figure.caption.12}{}}
\newlabel{sub@sqmrs}{{b}{30}{Esquema específico de aprendizaje por refuerzo en el sistema de recomendación.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces  Aprendizaje por refuerzo en el sistema de recomendaci\IeC {\'o}n\relax }}{30}{figure.caption.12}}
\@writefile{thm}{\contentsline {problem}{{Problema}{4.2.{1}}{Sin historial}}{30}{problem.4.2.1}}
\newlabel{prob1}{{4.2.{1}}{30}{Plantamiento de los problemas}{problem.4.2.1}{}}
\@writefile{thm}{\contentsline {problem}{{Problema}{4.2.{2}}{Con historial}}{30}{problem.4.2.2}}
\newlabel{prob2}{{4.2.{2}}{30}{Plantamiento de los problemas}{problem.4.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Metodolog\IeC {\'\i }a}{30}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Selecci\IeC {\'o}n de estado inicial}{30}{subsection.4.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Inicializaci\IeC {\'o}n de la funci\IeC {\'o}n valor estado-acci\IeC {\'o}n}{30}{subsection.4.3.2}}
\newlabel{InitQ}{{4.3.2}{30}{Inicialización de la función valor estado-acción}{subsection.4.3.2}{}}
\@writefile{thm}{\contentsline {thm}{{Teorema}{4.3.{1}}{}}{30}{thm.4.3.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces \emph  {Batch Q-learning }\relax }}{31}{algorithm.4}}
\newlabel{Qlearning}{{4}{31}{\emph {Batch Q-learning }\relax }{algorithm.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Pol\IeC {\'\i }tica utilizada}{31}{subsection.4.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Selecci\IeC {\'o}n de peliculas desde un pol\IeC {\'\i }tica dada}{31}{subsection.4.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Resultados num\IeC {\'e}ricos}{31}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Pol\IeC {\'\i }ticas de Referencia}{31}{subsection.4.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Pol\IeC {\'\i }ticas de referencias para un usuario concreto.\relax }}{32}{figure.caption.13}}
\newlabel{polref}{{4.2}{32}{Políticas de referencias para un usuario concreto.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Caso 1: Usuario sin historial previo}{32}{subsection.4.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Caso 2: Usuario con historial previo}{32}{subsection.4.4.3}}
\bibstyle{apalike}
\bibdata{Thesbib}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusiones}{33}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{banach1922operations}{Banach, 1922}
\bibcite{bellman1954theory}{Bellman, 1954}
\bibcite{bellman1957theory}{Bellman, 1957}
\bibcite{fujimoto2019off}{Fujimoto et\unhbox \voidb@x \penalty \@M \ al., 2019}
\bibcite{MovieLens}{Harper and Konstan, 2015}
\bibcite{LAZARIC}{Lazaric, 2013}
\bibcite{lops2011content}{Lops et\unhbox \voidb@x \penalty \@M \ al., 2011}
\bibcite{MATPCA}{{MATLAB Machine Learning Toolbox}, 2012}
\bibcite{schafer2007collaborative}{Schafer et\unhbox \voidb@x \penalty \@M \ al., 2007}
\bibcite{shani2005mdp}{Shani et\unhbox \voidb@x \penalty \@M \ al., 2005}
\bibcite{sutton2018reinforcement}{Sutton and Barto, 2018}
\bibcite{WikiRF}{{Wikipedia}, 2017}
\ttl@finishall
